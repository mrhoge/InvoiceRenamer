"""
é¸æŠç¯„å›²åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (v6)

PDFãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ä¸Šã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã—ãŸç¯„å›²å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚„ç”»åƒã‚’åˆ†æã—ã€
OCRå‡¦ç†ã‚’å«ã‚€é«˜åº¦ãªæƒ…å ±æŠ½å‡ºã‚’è¡Œã†ã€‚

ä¸»ãªæ©Ÿèƒ½:
- Qtåº§æ¨™ã‹ã‚‰PDFåº§æ¨™ã¸ã®å¤‰æ›ï¼ˆã‚ºãƒ¼ãƒ å¯¾å¿œï¼‰
- ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ã®æŠ½å‡ºã¨åˆ†æ
- ç”»åƒè¦ç´ ã®æŠ½å‡ºã¨OCRå‡¦ç†
- èª­ã¿é †ã®è‡ªå‹•åˆ¤å®š
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’è€ƒæ…®ã—ãŸé«˜é€Ÿãƒ¢ãƒ¼ãƒ‰

Copyright (C) 2023-2025 mrhoge

This file is part of InvoiceRenamer.

InvoiceRenamer is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed WITHOUT ANY WARRANTY; for more details see
the LICENSE file in the distribution root.
"""
from typing import List, Dict, Tuple, Optional, Union
from dataclasses import dataclass
import fitz  # PyMuPDF
import pytesseract
from PIL import Image
import io
from PySide6.QtCore import QRect
from invoice_renamer.utils.logger import setup_logger
from invoice_renamer.utils.error_handler import ErrorHandler, ErrorType
from invoice_renamer.logic.config_manager import ConfigManager


@dataclass
class AnalysisResult:
    """åˆ†æçµæœã‚’æ ¼ç´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹

    Attributes:
        text (str): æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        element_type (str): è¦ç´ ã‚¿ã‚¤ãƒ— ('text', 'image', 'mixed', 'diagnostic', 'error')
        confidence (float): OCRä¿¡é ¼åº¦ï¼ˆ0.0ã€œ1.0ï¼‰
        bbox (Tuple[float, float, float, float]): ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ (x0, y0, x1, y1)
        reading_order (int): èª­ã¿é †ï¼ˆä¸Šã‹ã‚‰å·¦ã‹ã‚‰é †ã«ç•ªå·ä»˜ã‘ï¼‰
    """
    text: str
    element_type: str  # 'text', 'image', 'mixed'
    confidence: float
    bbox: Tuple[float, float, float, float]  # (x0, y0, x1, y1)
    reading_order: int


@dataclass
class SelectionData:
    """é¸æŠç¯„å›²æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹

    Attributes:
        rect (QRect): Qtåº§æ¨™ç³»ã§ã®é¸æŠçŸ©å½¢
        page_number (int): PDFã®ãƒšãƒ¼ã‚¸ç•ªå·ï¼ˆ0ã‹ã‚‰å§‹ã¾ã‚‹ï¼‰
        pdf_path (str): PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    rect: QRect
    page_number: int
    pdf_path: str


class SelectionAnalyzer:
    """PDFå†…ã®é¸æŠç¯„å›²ã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹

    PDFãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ã§é¸æŠã•ã‚ŒãŸç¯„å›²å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚’æŠ½å‡ºãƒ»åˆ†æã™ã‚‹ã€‚
    ã‚ºãƒ¼ãƒ å¯¾å¿œã®åº§æ¨™å¤‰æ›ã€OCRå‡¦ç†ã€èª­ã¿é †åˆ¤å®šãªã©ã®æ©Ÿèƒ½ã‚’æä¾›ã€‚

    Attributes:
        logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        error_handler (ErrorHandler): ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        config_manager (ConfigManager): è¨­å®šç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """

    def __init__(self):
        self.logger = setup_logger('invoice_renamer.selection_analyzer')
        self.error_handler = ErrorHandler(self.logger)
        self.config_manager = ConfigManager()
        
    def analyze_selection(self, selection: SelectionData, analysis_params: dict = None, quick_mode: bool = False) -> List[AnalysisResult]:
        """
        é¸æŠç¯„å›²å†…ã®è¦ç´ ã‚’åˆ†æã—ã€çµæœã‚’è¿”ã™
        
        Args:
            selection (SelectionData): é¸æŠç¯„å›²æƒ…å ±
            analysis_params (dict): åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (zoom_scale, preview_sizeç­‰)
            quick_mode (bool): é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼ˆè©³ç´°ãƒ­ã‚°ã‚’çœç•¥ï¼‰
            
        Returns:
            List[AnalysisResult]: åˆ†æçµæœã®ãƒªã‚¹ãƒˆ
        """
        try:
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
            if not self._check_memory_usage():
                self.logger.warning("ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„ãŸã‚ã€é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
                quick_mode = True
            
            doc = fitz.open(selection.pdf_path)
            page = doc[selection.page_number]
            
            # åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
            if analysis_params is None:
                analysis_params = {}
            zoom_scale = analysis_params.get('zoom_scale', 1.0)
            preview_size = analysis_params.get('preview_size', (800, 600))
            ocr_language = analysis_params.get('ocr_language', 'jpn+eng')
            
            # åˆ†æãƒ¢ãƒ¼ãƒ‰ã®çŠ¶æ…‹ã‚’å¸¸ã«ãƒ­ã‚°å‡ºåŠ›
            self.logger.info(f"ğŸ” SelectionAnalyzer - åˆ†æãƒ¢ãƒ¼ãƒ‰: {'è©³ç´°' if not quick_mode else 'é«˜é€Ÿ'} (quick_mode={quick_mode})")
            
            # Qtåº§æ¨™ã‚’PDFåº§æ¨™ã«å¤‰æ›ï¼ˆã‚ºãƒ¼ãƒ ã‚’è€ƒæ…®ï¼‰
            pdf_rect = self._convert_qt_to_pdf_coords_with_zoom(selection.rect, page, zoom_scale, preview_size, quick_mode)
            
            if not quick_mode:
                # è©³ç´°ãªè¨ºæ–­æƒ…å ±ã‚’å‡ºåŠ›ï¼ˆè©³ç´°ãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
                self.logger.info("=" * 60)
                self.logger.info(f"é¸æŠç¯„å›²åˆ†æé–‹å§‹ï¼ˆè©³ç´°ãƒ¢ãƒ¼ãƒ‰ï¼‰")
                self.logger.info(f"Qté¸æŠç¯„å›²: x={selection.rect.x()}, y={selection.rect.y()}, w={selection.rect.width()}, h={selection.rect.height()}")
                self.logger.info(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µã‚¤ã‚º: {preview_size}")
                self.logger.info(f"PDFç¯„å›²: {pdf_rect}")
                self.logger.info(f"ãƒšãƒ¼ã‚¸ã‚µã‚¤ã‚º: {page.rect}")
            
            # é¸æŠç¯„å›²å†…ã®è¦ç´ ã‚’å–å¾—ï¼ˆé«˜é€Ÿãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰
            text_elements = self._extract_text_elements(page, pdf_rect, quick_mode)
            image_elements = self._extract_image_elements_optimized(page, pdf_rect, quick_mode)
            
            if not quick_mode:
                self.logger.info(f"æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆè¦ç´ : {len(text_elements)}å€‹")
                self.logger.info(f"æŠ½å‡ºã•ã‚ŒãŸç”»åƒè¦ç´ : {len(image_elements)}å€‹")

            # åˆ†æçµæœã‚’çµ±åˆ
            results = []

            # ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ã‚’å‡¦ç†
            text_results = self._process_text_elements(text_elements)
            results.extend(text_results)

            # ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯OCRã‚’ã‚¹ã‚­ãƒƒãƒ—
            # ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå‹PDFã®å ´åˆã€OCRã¯ä¸è¦ã§ç²¾åº¦ã‚‚ä½ã„ãŸã‚ï¼‰
            if len(text_results) > 0:
                if not quick_mode:
                    self.logger.info(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ãŒ{len(text_results)}å€‹æ¤œå‡ºã•ã‚ŒãŸãŸã‚ã€OCRå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            else:
                # ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ãŒãªã„å ´åˆã®ã¿OCRã‚’å®Ÿè¡Œ
                if not quick_mode:
                    self.logger.info("ğŸ“· ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸãŸã‚ã€OCRå‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™")
                results.extend(self._process_image_elements_optimized(image_elements, page, ocr_language, quick_mode))

            # èª­ã¿é †ã§ã‚½ãƒ¼ãƒˆ
            results = self._sort_by_reading_order(results)
            
            # çµæœãŒç©ºã®å ´åˆã§ã‚‚ã€è¨ºæ–­æƒ…å ±ã‚’å«ã‚€çµæœã‚’è¿”ã™
            if not results:
                if not quick_mode:
                    self.logger.info("åˆ†æçµæœãŒç©ºã®ãŸã‚ã€è¨ºæ–­çµæœã‚’ä½œæˆ")
                    diagnostic_info = self._create_diagnostic_info(page, pdf_rect, preview_size, selection.rect)
                else:
                    diagnostic_info = "é¸æŠç¯„å›²å†…ã«ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                    
                default_result = AnalysisResult(
                    text=diagnostic_info,
                    element_type="diagnostic",
                    confidence=0.0,
                    bbox=(pdf_rect.x0, pdf_rect.y0, pdf_rect.x1, pdf_rect.y1),
                    reading_order=0
                )
                results = [default_result]
            
            if not quick_mode:
                self.logger.info("=" * 60)
            doc.close()
            return results
            
        except Exception as e:
            self.logger.error(f"é¸æŠç¯„å›²åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã§ã‚‚ç©ºã§ãªã„çµæœã‚’è¿”ã™
            error_result = AnalysisResult(
                text=f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}",
                element_type="error",
                confidence=0.0,
                bbox=(0, 0, 0, 0),
                reading_order=0
            )
            return [error_result]
    
    def _convert_qt_to_pdf_coords_with_zoom(self, qt_rect: QRect, page: fitz.Page, zoom_scale: float, preview_size: tuple, quick_mode: bool = False) -> fitz.Rect:
        """Qtåº§æ¨™ã‚’PDFåº§æ¨™ã«å¤‰æ›ï¼ˆã‚ºãƒ¼ãƒ è€ƒæ…®ï¼‰

        Args:
            qt_rect (QRect): Qtåº§æ¨™ç³»ã®çŸ©å½¢
            page (fitz.Page): PDFãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            zoom_scale (float): ã‚ºãƒ¼ãƒ å€ç‡
            preview_size (tuple): ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã‚µã‚¤ã‚º (width, height)
            quick_mode (bool): é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ­ã‚°ã‚’ç°¡ç•¥åŒ–ï¼‰

        Returns:
            fitz.Rect: PDFåº§æ¨™ç³»ã«å¤‰æ›ã•ã‚ŒãŸçŸ©å½¢

        Note:
            ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’è€ƒæ…®ã—ãŸåº§æ¨™å¤‰æ›ã‚’è¡Œã„ã€
            ãƒšãƒ¼ã‚¸ç¯„å›²å¤–ã®åº§æ¨™ã¯è‡ªå‹•çš„ã«ã‚¯ãƒªãƒƒãƒ—ã•ã‚Œã‚‹
        """
        # ãƒšãƒ¼ã‚¸ã®ã‚µã‚¤ã‚ºã‚’å–å¾—
        page_rect = page.rect
        
        # ã‚ºãƒ¼ãƒ ã‚’è€ƒæ…®ã—ã¦Qtåº§æ¨™ã‚’å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
        actual_qt_rect = QRect(
            int(qt_rect.x() / zoom_scale),
            int(qt_rect.y() / zoom_scale),
            int(qt_rect.width() / zoom_scale),
            int(qt_rect.height() / zoom_scale)
        )
        
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºã‚‚ã‚ºãƒ¼ãƒ ã‚’è€ƒæ…®ã—ã¦èª¿æ•´
        preview_width, preview_height = preview_size
        actual_preview_width = int(preview_width / zoom_scale)
        actual_preview_height = int(preview_height / zoom_scale)
        
        # å®Ÿéš›ã®è¡¨ç¤ºæ™‚ã®ã‚¹ã‚±ãƒ¼ãƒ«è¨ˆç®—ï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’è€ƒæ…®ï¼‰
        page_aspect = page_rect.width / page_rect.height
        preview_aspect = actual_preview_width / actual_preview_height
        
        if page_aspect > preview_aspect:
            # ãƒšãƒ¼ã‚¸ãŒæ¨ªé•·ï¼šå¹…ã«åˆã‚ã›ã¦ã‚¹ã‚±ãƒ¼ãƒ«
            scale = page_rect.width / actual_preview_width
            actual_display_height = page_rect.height / scale
            y_offset = (actual_preview_height - actual_display_height) / 2
            x_offset = 0
        else:
            # ãƒšãƒ¼ã‚¸ãŒç¸¦é•·ï¼šé«˜ã•ã«åˆã‚ã›ã¦ã‚¹ã‚±ãƒ¼ãƒ«
            scale = page_rect.height / actual_preview_height
            actual_display_width = page_rect.width / scale
            x_offset = (actual_preview_width - actual_display_width) / 2
            y_offset = 0
        
        # Qtåº§æ¨™ã‚’PDFåº§æ¨™ã«å¤‰æ›ï¼ˆã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è€ƒæ…®ï¼‰
        pdf_x0 = (actual_qt_rect.x() - x_offset) * scale
        pdf_y0 = (actual_qt_rect.y() - y_offset) * scale
        pdf_x1 = (actual_qt_rect.x() + actual_qt_rect.width() - x_offset) * scale
        pdf_y1 = (actual_qt_rect.y() + actual_qt_rect.height() - y_offset) * scale
        
        # åº§æ¨™å€¤ã®æ¤œè¨¼ã¨è£œæ­£
        if pdf_x0 < 0 or pdf_y0 < 0 or pdf_x1 > page_rect.width or pdf_y1 > page_rect.height:
            if not quick_mode:
                self.logger.warning(f"åº§æ¨™ãŒãƒšãƒ¼ã‚¸ç¯„å›²ã‚’è¶…ãˆã¦ã„ã¾ã™: PDF({pdf_x0:.2f}, {pdf_y0:.2f}, {pdf_x1:.2f}, {pdf_y1:.2f}) vs Page({page_rect.width:.2f}, {page_rect.height:.2f})")
            # ãƒšãƒ¼ã‚¸ç¯„å›²å†…ã«ã‚¯ãƒªãƒƒãƒ—
            pdf_x0 = max(0, pdf_x0)
            pdf_y0 = max(0, pdf_y0)
            pdf_x1 = min(page_rect.width, pdf_x1)
            pdf_y1 = min(page_rect.height, pdf_y1)
        
        # ç¯„å›²ã®æœ‰åŠ¹æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        if pdf_x1 <= pdf_x0 or pdf_y1 <= pdf_y0:
            if not quick_mode:
                self.logger.error(f"ç„¡åŠ¹ãªåº§æ¨™ç¯„å›²: PDF({pdf_x0:.2f}, {pdf_y0:.2f}, {pdf_x1:.2f}, {pdf_y1:.2f})")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å°ã•ãªç¯„å›²ã‚’è¿”ã™
            return fitz.Rect(10, 10, 50, 50)
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
        if not quick_mode:
            self.logger.info(f"åº§æ¨™å¤‰æ›è©³ç´° (ã‚ºãƒ¼ãƒ è€ƒæ…®):")
            self.logger.info(f"  ã‚ºãƒ¼ãƒ å€ç‡: {zoom_scale:.3f}")
            self.logger.info(f"  å…ƒQtåº§æ¨™: ({qt_rect.x()}, {qt_rect.y()}, {qt_rect.width()}, {qt_rect.height()})")
            self.logger.info(f"  èª¿æ•´å¾ŒQtåº§æ¨™: ({actual_qt_rect.x()}, {actual_qt_rect.y()}, {actual_qt_rect.width()}, {actual_qt_rect.height()})")
            self.logger.info(f"  ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µã‚¤ã‚º: {preview_size} -> ({actual_preview_width}, {actual_preview_height})")
            self.logger.info(f"  ãƒšãƒ¼ã‚¸ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {page_aspect:.3f}")
            self.logger.info(f"  ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {preview_aspect:.3f}")
            self.logger.info(f"  ã‚¹ã‚±ãƒ¼ãƒ«: {scale:.3f}")
            self.logger.info(f"  ã‚ªãƒ•ã‚»ãƒƒãƒˆ: x={x_offset:.1f}, y={y_offset:.1f}")
            self.logger.info(f"  æœ€çµ‚PDFåº§æ¨™: ({pdf_x0:.2f}, {pdf_y0:.2f}, {pdf_x1:.2f}, {pdf_y1:.2f})")
            self.logger.info(f"  ãƒšãƒ¼ã‚¸ã‚µã‚¤ã‚º: ({page_rect.width:.2f}, {page_rect.height:.2f})")
        
        final_rect = fitz.Rect(pdf_x0, pdf_y0, pdf_x1, pdf_y1)
        
        if not quick_mode:
            self.logger.info(f"  æ¤œè¨¼å¾Œã®æœ€çµ‚ç¯„å›²: {final_rect}")
        
        return final_rect
    
    def _convert_qt_to_pdf_coords(self, qt_rect: QRect, page: fitz.Page, preview_size: tuple = None, quick_mode: bool = False) -> fitz.Rect:
        """Qtåº§æ¨™ã‚’PDFåº§æ¨™ã«å¤‰æ›ï¼ˆæ—§ãƒ¡ã‚½ãƒƒãƒ‰äº’æ›ç”¨ï¼‰"""
        # ã‚ºãƒ¼ãƒ å€ç‡ã‚’1.0ã¨ã—ã¦æ–°ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
        if preview_size is None:
            preview_size = (800, 600)
        return self._convert_qt_to_pdf_coords_with_zoom(qt_rect, page, 1.0, preview_size, quick_mode)
    
    def _extract_text_elements(self, page: fitz.Page, rect: fitz.Rect, quick_mode: bool = False) -> List[Dict]:
        """é¸æŠç¯„å›²å†…ã®ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ã‚’æŠ½å‡º"""
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‚’å–å¾—ï¼ˆé¸æŠç¯„å›²ã§ã‚¯ãƒªãƒƒãƒ—ï¼‰
            text_dict = page.get_text("dict", clip=rect)
            text_elements = []
            
            for block in text_dict["blocks"]:
                if "lines" in block:  # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯
                    for line in block["lines"]:
                        for span in line["spans"]:
                            bbox = span["bbox"]
                            text = span["text"].strip()
                            if text:
                                text_elements.append({
                                    "text": text,
                                    "bbox": bbox,
                                    "font": span.get("font", ""),
                                    "size": span.get("size", 0)
                                })
                                self.logger.info(f"ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ç™ºè¦‹: '{text}' at {bbox}")
            
            return text_elements
            
        except Exception as e:
            self.logger.error(f"ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _extract_image_elements_optimized(self, page: fitz.Page, rect: fitz.Rect, quick_mode: bool = False) -> List[Dict]:
        """é¸æŠç¯„å›²å†…ã®ç”»åƒè¦ç´ ã‚’æœ€é©åŒ–ã—ã¦æŠ½å‡ºï¼ˆé«˜é€Ÿç‰ˆï¼‰"""
        try:
            image_elements = []
            
            if not quick_mode:
                self.logger.info(f"--- é¸æŠç¯„å›²ç”»åƒæŠ½å‡ºï¼ˆæœ€é©åŒ–ç‰ˆï¼‰ ---")
                self.logger.info(f"é¸æŠç¯„å›²: {rect}")
            
            # æ–¹æ³•1: é¸æŠç¯„å›²ã‚’ä½è§£åƒåº¦ã§ç›´æ¥ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼ˆé«˜é€ŸåŒ–ï¼‰
            try:
                # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã§ã¯1.5å€ã€é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§ã¯2å€è§£åƒåº¦
                matrix_scale = 1.5 if quick_mode else 2.0
                pix = page.get_pixmap(clip=rect, matrix=fitz.Matrix(matrix_scale, matrix_scale))
                img_data = pix.tobytes("png")
                
                if len(img_data) > 500:  # æœ€å°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆé€šå¸¸ã‚ˆã‚Šç·©å’Œï¼‰
                    image_elements.append({
                        "image_data": img_data,
                        "bbox": tuple(rect),
                        "xref": None,
                        "ext": "png",
                        "index": 0,
                        "method": "direct_rendering_optimized",
                        "crop_info": {
                            "original_rect": rect,
                            "cropped": True,
                            "quick_mode": quick_mode
                        }
                    })
                    if not quick_mode:
                        self.logger.info(f"æœ€é©åŒ–ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æˆåŠŸ: {len(img_data)} bytes")
                else:
                    if not quick_mode:
                        self.logger.info("æœ€é©åŒ–ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã‚‹")
                    
            except Exception as render_error:
                if not quick_mode:
                    self.logger.warning(f"æœ€é©åŒ–ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¤±æ•—: {str(render_error)}")
            
            # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã§ã¯æ—¢å­˜ç”»åƒã®è©³ç´°åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—
            if not quick_mode:
                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®ã¿: æ—¢å­˜ã®ç”»åƒè¦ç´ ã‹ã‚‰é¸æŠç¯„å›²ã¨é‡è¤‡ã™ã‚‹ã‚‚ã®ã‚’æŠ½å‡º
                try:
                    image_list = page.get_images()
                    if len(image_list) > 0:
                        self.logger.info(f"ãƒšãƒ¼ã‚¸å†…ã®ç”»åƒæ•°: {len(image_list)}")
                        
                        for img_index, img in enumerate(image_list[:3]):  # æœ€å¤§3ã¤ã¾ã§ã«åˆ¶é™
                            try:
                                xref = img[0]
                                img_rect = page.get_image_bbox(xref)
                                
                                # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡ç•¥åŒ–ï¼‰
                                if rect.intersects(img_rect):
                                    try:
                                        base_image = page.parent.extract_image(xref)
                                        img_data = base_image["image"]
                                        
                                        if len(img_data) > 1000:
                                            image_elements.append({
                                                "image_data": img_data,
                                                "bbox": tuple(img_rect),
                                                "xref": xref,
                                                "ext": base_image["ext"],
                                                "index": img_index + 1,
                                                "method": "existing_image_intersection"
                                            })
                                            
                                    except Exception as extract_error:
                                        self.logger.warning(f"æ—¢å­˜ç”»åƒæŠ½å‡ºå¤±æ•— {img_index + 1}: {str(extract_error)}")
                                        
                            except Exception as img_error:
                                continue
                                
                except Exception as list_error:
                    self.logger.warning(f"ç”»åƒãƒªã‚¹ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(list_error)}")
            
            if not quick_mode:
                self.logger.info(f"æœ€é©åŒ–æŠ½å‡ºå®Œäº†: {len(image_elements)}å€‹ã®ç”»åƒè¦ç´ ")
            
            return image_elements
            
        except Exception as e:
            self.logger.error(f"æœ€é©åŒ–ç”»åƒæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _extract_image_elements_with_cropping(self, page: fitz.Page, rect: fitz.Rect) -> List[Dict]:
        """é¸æŠç¯„å›²å†…ã®ç”»åƒè¦ç´ ã‚’æŠ½å‡ºã—ã€é¸æŠç¯„å›²ã§åˆ‡ã‚ŠæŠœã"""
        try:
            image_elements = []
            
            self.logger.info(f"--- é¸æŠç¯„å›²ç”»åƒæŠ½å‡ºï¼ˆåˆ‡ã‚ŠæŠœãã‚ã‚Šï¼‰ ---")
            self.logger.info(f"é¸æŠç¯„å›²: {rect}")
            
            # æ–¹æ³•1: é¸æŠç¯„å›²ã‚’ç”»åƒã¨ã—ã¦ç›´æ¥ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼ˆæœ€ã‚‚ç¢ºå®Ÿï¼‰
            try:
                # é¸æŠç¯„å›²ã®ç”»åƒã‚’ç›´æ¥å–å¾—
                pix = page.get_pixmap(clip=rect, matrix=fitz.Matrix(2.0, 2.0))  # 2å€è§£åƒåº¦
                img_data = pix.tobytes("png")
                
                if len(img_data) > 1000:  # æœ€å°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                    image_elements.append({
                        "image_data": img_data,
                        "bbox": tuple(rect),
                        "xref": None,  # ç›´æ¥ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ãªã®ã§xrefã¯ãªã—
                        "ext": "png",
                        "index": 0,
                        "method": "direct_rendering",
                        "crop_info": {
                            "original_rect": rect,
                            "cropped": True
                        }
                    })
                    self.logger.info(f"ç›´æ¥ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æˆåŠŸ: {len(img_data)} bytes")
                else:
                    self.logger.info("ç›´æ¥ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã‚‹")
                    
            except Exception as render_error:
                self.logger.warning(f"ç›´æ¥ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¤±æ•—: {str(render_error)}")
            
            # æ–¹æ³•2: æ—¢å­˜ã®ç”»åƒè¦ç´ ã‹ã‚‰é¸æŠç¯„å›²ã¨é‡è¤‡ã™ã‚‹ã‚‚ã®ã‚’æŠ½å‡ºã—ã¦åˆ‡ã‚ŠæŠœã
            try:
                image_list = page.get_images()
                self.logger.info(f"ãƒšãƒ¼ã‚¸å†…ã®ç”»åƒæ•°: {len(image_list)}")
                
                for img_index, img in enumerate(image_list):
                    try:
                        xref = img[0]
                        
                        # ç”»åƒã®ä½ç½®ã‚’å–å¾—
                        try:
                            img_rect = page.get_image_bbox(xref)
                            self.logger.info(f"ç”»åƒ {img_index + 1}: ä½ç½® {img_rect}")
                        except Exception as bbox_error:
                            self.logger.warning(f"ç”»åƒ {img_index + 1}: ä½ç½®å–å¾—å¤±æ•— - {str(bbox_error)}")
                            continue  # ä½ç½®ãŒå–å¾—ã§ããªã„ç”»åƒã¯ã‚¹ã‚­ãƒƒãƒ—
                        
                        # é¸æŠç¯„å›²ã¨ã®é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯
                        if rect.intersects(img_rect):
                            intersection = rect & img_rect
                            if intersection.width > 5 and intersection.height > 5:  # æœ€å°é‡è¤‡ã‚µã‚¤ã‚º
                                self.logger.info(f"ç”»åƒ {img_index + 1}: é¸æŠç¯„å›²ã¨é‡è¤‡ {intersection}")
                                
                                # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                                try:
                                    base_image = page.parent.extract_image(xref)
                                    original_image_data = base_image["image"]
                                    
                                    # PIL Imageã§é–‹ã„ã¦åˆ‡ã‚ŠæŠœã
                                    pil_image = Image.open(io.BytesIO(original_image_data))
                                    
                                    # ç”»åƒåº§æ¨™ã§ã®åˆ‡ã‚ŠæŠœãç¯„å›²ã‚’è¨ˆç®—
                                    # æ³¨æ„: PDFåº§æ¨™ã¨ç”»åƒåº§æ¨™ã¯ç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
                                    img_width, img_height = pil_image.size
                                    
                                    # PDFåº§æ¨™ã‚’ç”»åƒåº§æ¨™ã«å¤‰æ›
                                    # ç”»åƒã®å®Ÿéš›ã®ç¯„å›² (img_rect) ã‚’ç”»åƒã‚µã‚¤ã‚º (img_width, img_height) ã«ãƒãƒƒãƒ”ãƒ³ã‚°
                                    scale_x = img_width / img_rect.width if img_rect.width > 0 else 1
                                    scale_y = img_height / img_rect.height if img_rect.height > 0 else 1
                                    
                                    # é¸æŠç¯„å›²ã‚’ç”»åƒåº§æ¨™ã«å¤‰æ›
                                    crop_x0 = max(0, int((rect.x0 - img_rect.x0) * scale_x))
                                    crop_y0 = max(0, int((rect.y0 - img_rect.y0) * scale_y))
                                    crop_x1 = min(img_width, int((rect.x1 - img_rect.x0) * scale_x))
                                    crop_y1 = min(img_height, int((rect.y1 - img_rect.y0) * scale_y))
                                    
                                    self.logger.info(f"åˆ‡ã‚ŠæŠœãåº§æ¨™: ({crop_x0}, {crop_y0}, {crop_x1}, {crop_y1})")
                                    
                                    # æœ‰åŠ¹ãªåˆ‡ã‚ŠæŠœãç¯„å›²ã‹ãƒã‚§ãƒƒã‚¯
                                    if crop_x1 > crop_x0 and crop_y1 > crop_y0:
                                        # ç”»åƒã‚’åˆ‡ã‚ŠæŠœã
                                        cropped_image = pil_image.crop((crop_x0, crop_y0, crop_x1, crop_y1))
                                        
                                        # PNGå½¢å¼ã§ä¿å­˜
                                        img_buffer = io.BytesIO()
                                        cropped_image.save(img_buffer, format='PNG')
                                        cropped_data = img_buffer.getvalue()
                                        
                                        image_elements.append({
                                            "image_data": cropped_data,
                                            "bbox": tuple(intersection),  # é‡è¤‡é ˜åŸŸã‚’bboxã¨ã—ã¦ä½¿ç”¨
                                            "xref": xref,
                                            "ext": "png",
                                            "index": img_index,
                                            "method": "cropped_from_existing",
                                            "crop_info": {
                                                "original_rect": img_rect,
                                                "crop_rect": (crop_x0, crop_y0, crop_x1, crop_y1),
                                                "cropped": True,
                                                "original_size": pil_image.size,
                                                "cropped_size": cropped_image.size
                                            }
                                        })
                                        
                                        self.logger.info(f"ç”»åƒ {img_index + 1} ã‚’åˆ‡ã‚ŠæŠœã: {cropped_image.size}")
                                    else:
                                        self.logger.warning(f"ç”»åƒ {img_index + 1}: ç„¡åŠ¹ãªåˆ‡ã‚ŠæŠœãç¯„å›²")
                                        
                                except Exception as crop_error:
                                    self.logger.error(f"ç”»åƒ {img_index + 1} åˆ‡ã‚ŠæŠœãã‚¨ãƒ©ãƒ¼: {str(crop_error)}")
                            else:
                                self.logger.info(f"ç”»åƒ {img_index + 1}: é‡è¤‡ãŒå°ã•ã™ãã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                        else:
                            self.logger.info(f"ç”»åƒ {img_index + 1}: é¸æŠç¯„å›²ã¨é‡è¤‡ãªã—")
                            
                    except Exception as img_error:
                        self.logger.error(f"ç”»åƒ {img_index + 1} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(img_error)}")
                        continue
                        
            except Exception as extract_error:
                self.logger.error(f"æ—¢å­˜ç”»åƒæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(extract_error)}")
            
            self.logger.info(f"æœ€çµ‚çš„ã«æŠ½å‡ºã•ã‚ŒãŸç”»åƒè¦ç´ : {len(image_elements)}å€‹")
            return image_elements
            
        except Exception as e:
            self.logger.error(f"ç”»åƒè¦ç´ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _create_diagnostic_info(self, page: fitz.Page, pdf_rect: fitz.Rect, preview_size: tuple, qt_rect: QRect) -> str:
        """è¨ºæ–­æƒ…å ±ã‚’ä½œæˆ"""
        info_parts = []
        info_parts.append("ã€è¨ºæ–­æƒ…å ±ã€‘")
        info_parts.append(f"Qté¸æŠ: {qt_rect.x()},{qt_rect.y()},{qt_rect.width()},{qt_rect.height()}")
        info_parts.append(f"PDFåº§æ¨™: {pdf_rect}")
        info_parts.append(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µã‚¤ã‚º: {preview_size}")
        
        # ç”»åƒæƒ…å ±ï¼ˆã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰
        try:
            image_list = page.get_images()
            info_parts.append(f"ãƒšãƒ¼ã‚¸å†…ç”»åƒæ•°: {len(image_list)}")
            
            # ç›´æ¥ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ
            try:
                pix = page.get_pixmap(clip=pdf_rect)
                info_parts.append(f"ç›´æ¥ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚µã‚¤ã‚º: {pix.width}x{pix.height}")
            except Exception as render_error:
                info_parts.append(f"ç›´æ¥ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(render_error)[:50]}...")
            
            for i, img in enumerate(image_list[:3]):  # æœ€åˆã®3ã¤ã¾ã§
                try:
                    xref = img[0]
                    try:
                        img_rect = page.get_image_bbox(xref)
                        intersects = pdf_rect.intersects(img_rect)
                        info_parts.append(f"ç”»åƒ{i+1}: {img_rect} (é‡è¤‡:{intersects})")
                    except Exception as bbox_error:
                        info_parts.append(f"ç”»åƒ{i+1}: ä½ç½®å–å¾—ã‚¨ãƒ©ãƒ¼ ({str(bbox_error)[:30]}...)")
                        
                except Exception as img_error:
                    info_parts.append(f"ç”»åƒ{i+1}: å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({str(img_error)[:30]}...)")
                
        except Exception as e:
            info_parts.append(f"ç”»åƒæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
        try:
            text = page.get_text(clip=pdf_rect)
            info_parts.append(f"ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(text)}")
            if text.strip():
                info_parts.append(f"ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«: {text[:50]}...")
        except Exception as e:
            info_parts.append(f"ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        return "\n".join(info_parts)
    
    def _process_text_elements(self, text_elements: List[Dict]) -> List[AnalysisResult]:
        """ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ã‚’å‡¦ç†"""
        results = []
        
        for element in text_elements:
            result = AnalysisResult(
                text=element["text"],
                element_type="text",
                confidence=1.0,  # ãƒ†ã‚­ã‚¹ãƒˆã¯ç¢ºå®Ÿ
                bbox=element["bbox"],
                reading_order=0  # å¾Œã§ã‚½ãƒ¼ãƒˆæ™‚ã«è¨­å®š
            )
            results.append(result)
        
        return results
    
    def _process_image_elements_optimized(self, image_elements: List[Dict], page: fitz.Page, ocr_language: str = 'jpn+eng', quick_mode: bool = False) -> List[AnalysisResult]:
        """ç”»åƒè¦ç´ ã‚’OCRå‡¦ç†ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
        results = []
        
        # å¤§é‡ã®ç”»åƒè¦ç´ ãŒã‚ã‚‹å ´åˆã¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ãƒã‚§ãƒƒã‚¯
        if len(image_elements) > 5 and not self._check_memory_usage():
            self.logger.warning("ãƒ¡ãƒ¢ãƒªä¸è¶³ã®ãŸã‚ã€OCRå‡¦ç†ã‚’åˆ¶é™ã—ã¾ã™")
            image_elements = image_elements[:3]  # æœ€åˆã®3ã¤ã®è¦ç´ ã®ã¿å‡¦ç†
        
        if not quick_mode:
            self.logger.info(f"OCRå‡¦ç†é–‹å§‹ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰: {len(image_elements)}å€‹ã®ç”»åƒè¦ç´ ")
        
        for idx, element in enumerate(image_elements):
            try:
                if not quick_mode:
                    self.logger.info(f"ç”»åƒè¦ç´  {element.get('index', idx)} ã®OCRå‡¦ç†ã‚’é–‹å§‹")
                
                # ç”»åƒã‚’PIL Imageã«å¤‰æ›ï¼ˆãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰
                try:
                    image_bytes = element["image_data"]
                    pil_image = Image.open(io.BytesIO(image_bytes))
                    
                    # ç”»åƒãŒå¤§ãã™ãã‚‹å ´åˆã¯ãƒªã‚µã‚¤ã‚º
                    if pil_image.size[0] * pil_image.size[1] > 4000000:  # 4M pixelsä»¥ä¸Š
                        self.logger.warning(f"ç”»åƒãŒå¤§ãã™ãã‚‹ãŸã‚ãƒªã‚µã‚¤ã‚ºã—ã¾ã™: {pil_image.size}")
                        max_dimension = 2000
                        ratio = min(max_dimension / pil_image.size[0], max_dimension / pil_image.size[1])
                        new_size = (int(pil_image.size[0] * ratio), int(pil_image.size[1] * ratio))
                        pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
                    
                    if not quick_mode:
                        self.logger.info(f"ç”»åƒã‚µã‚¤ã‚º: {pil_image.size}, ãƒ¢ãƒ¼ãƒ‰: {pil_image.mode}")
                        
                except MemoryError as me:
                    # ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼
                    self.error_handler.handle_error(me, ErrorType.MEMORY_ERROR, show_dialog=False)
                    self.logger.error(f"ç”»åƒå¤‰æ›ã§ãƒ¡ãƒ¢ãƒªä¸è¶³ (è¦ç´  {idx})")
                    continue
                except Exception as ie:
                    self.logger.error(f"ç”»åƒå¤‰æ›ã‚¨ãƒ©ãƒ¼ (è¦ç´  {idx}): {str(ie)}")
                    continue
                
                # OCRè¨­å®šï¼ˆæ—¥æœ¬èªå„ªå…ˆè¨­å®šï¼‰
                if quick_mode:
                    # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼šæ—¥æœ¬èªã¨è‹±èªã‚’ä½µç”¨ã€æ–‡å­—åˆ¶é™ã‚’æœ€å°é™ã«
                    ocr_config = '--oem 3 --psm 6 -c preserve_interword_spaces=1'
                else:
                    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼šæ—¥æœ¬èªå„ªå…ˆã§è©³ç´°è¨­å®š
                    ocr_config = (
                        '--oem 3 --psm 6 '
                        '-c preserve_interword_spaces=1 '
                        '-c tessedit_char_blacklist=Â§Â°Â¢Â£Â¤Â¥Â¦Â©Â«Â®Â±Â²Â³Â´ÂµÂ¶Â·Â¸Â¹ÂºÂ»Â¼Â½Â¾'
                    )
                
                # OCRå®Ÿè¡Œï¼ˆé¸æŠã•ã‚ŒãŸè¨€èªã§ï¼‰
                if ocr_language == 'auto':
                    # è‡ªå‹•æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰
                    text = self._auto_detect_language_ocr(pil_image, ocr_config, quick_mode)
                else:
                    # æŒ‡å®šã•ã‚ŒãŸè¨€èªã§OCRå®Ÿè¡Œ
                    text = pytesseract.image_to_string(pil_image, config=ocr_config, lang=ocr_language)
                    
                    # æ—¥æœ¬èªãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    if ocr_language == 'jpn+eng' and (not text.strip() or not self._contains_japanese_text(text)):
                        text_jpn = pytesseract.image_to_string(pil_image, config='--oem 3 --psm 6', lang='jpn')
                        if text_jpn.strip() and self._contains_japanese_text(text_jpn):
                            text = text_jpn
                            if not quick_mode:
                                self.logger.info(f"æ—¥æœ¬èªå°‚ç”¨OCRã§å†è©¦è¡Œ: '{text[:50]}{'...' if len(text) > 50 else ''}'")
                
                if text and text.strip():
                    confidence = 0.8 if quick_mode else 0.9  # é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã§ã¯ä¿¡é ¼åº¦ã‚’å°‘ã—ä¸‹ã’ã‚‹
                    result = AnalysisResult(
                        text=text.strip(),
                        element_type="image",
                        confidence=confidence,
                        bbox=element["bbox"],
                        reading_order=idx
                    )
                    results.append(result)
                    
                    if not quick_mode:
                        self.logger.info(f"OCRæˆåŠŸ: '{text.strip()[:30]}...'")
                else:
                    if not quick_mode:
                        self.logger.info("OCRçµæœãŒç©ºã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆãªã—")
                
            except Exception as e:
                # OCRã‚¨ãƒ©ãƒ¼ã‚’åˆ†é¡ã—ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                error_type = self.error_handler.classify_ocr_error(e)
                
                if not quick_mode:
                    self.logger.error(f"OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼ (è¦ç´  {idx}): {str(e)}")
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’è©¦è¡Œ
                fallback_result = self._try_ocr_fallback(pil_image, element, idx, quick_mode)
                if fallback_result:
                    results.append(fallback_result)
                
                continue
        
        if not quick_mode:
            self.logger.info(f"OCRå‡¦ç†å®Œäº†: {len(results)}å€‹ã®çµæœ")
        
        return results
    
    def _process_image_elements(self, image_elements: List[Dict], page: fitz.Page) -> List[AnalysisResult]:
        """ç”»åƒè¦ç´ ã‚’OCRå‡¦ç†"""
        results = []
        
        self.logger.info(f"OCRå‡¦ç†é–‹å§‹: {len(image_elements)}å€‹ã®ç”»åƒè¦ç´ ")
        
        for idx, element in enumerate(image_elements):
            try:
                self.logger.info(f"ç”»åƒè¦ç´  {element.get('index', idx)} ã®OCRå‡¦ç†ã‚’é–‹å§‹")
                
                # ç”»åƒã‚’PIL Imageã«å¤‰æ›
                image_bytes = element["image_data"]
                pil_image = Image.open(io.BytesIO(image_bytes))
                
                self.logger.info(f"ç”»åƒã‚µã‚¤ã‚º: {pil_image.size}, ãƒ¢ãƒ¼ãƒ‰: {pil_image.mode}")
                
                # åˆ‡ã‚ŠæŠœãæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
                crop_info = element.get("crop_info", {})
                method = element.get("method", "unknown")
                self.logger.info(f"å‡¦ç†æ–¹æ³•: {method}")
                if crop_info:
                    self.logger.info(f"åˆ‡ã‚ŠæŠœãæƒ…å ±: {crop_info}")
                
                # ç”»åƒãŒå°ã•ã™ãã‚‹å ´åˆã§ã‚‚çµæœã‚’ä½œæˆ
                if pil_image.width < 10 or pil_image.height < 10:
                    self.logger.info("ç”»åƒãŒå°ã•ã™ãã¾ã™ãŒã€çµæœã‚’ä½œæˆã—ã¾ã™")
                    result = AnalysisResult(
                        text=f"ç”»åƒãŒå°ã•ã™ãã¾ã™ (ã‚µã‚¤ã‚º: {pil_image.size}, æ–¹æ³•: {method})",
                        element_type="image",
                        confidence=0.0,
                        bbox=element["bbox"],
                        reading_order=0
                    )
                    results.append(result)
                    continue
                
                # OCRå‡¦ç†ã‚’è©¦è¡Œ
                ocr_success = False
                extracted_text = ""
                confidence = 0.0
                
                try:
                    # TesseractãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                    self.logger.info("Tesseractã§ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’é–‹å§‹")
                    
                    # ç”»åƒå‰å‡¦ç†ã‚’è©¦è¡Œ
                    processed_images = self._preprocess_image_for_ocr(pil_image)
                    
                    # æœ€é©åŒ–ã•ã‚ŒãŸOCRè¨­å®šï¼ˆå‡¦ç†æ™‚é–“çŸ­ç¸® + å“è³ªå‘ä¸Šï¼‰
                    # OCRè¨€èªè¨­å®šã«å¿œã˜ã¦è¨­å®šã‚’å¤‰æ›´
                    ocr_configs = self._get_ocr_configs_for_language(ocr_language)
                    
                    best_text = ""
                    best_confidence = 0
                    
                    for config_idx, ocr_config in enumerate(ocr_configs):
                        try:
                            # å„ç”»åƒå‰å‡¦ç†ç‰ˆã§OCRã‚’è©¦è¡Œ
                            for img_variant_name, img_variant in processed_images.items():
                                try:
                                    test_text = pytesseract.image_to_string(
                                        img_variant,
                                        lang=ocr_config['lang'],
                                        config=ocr_config['config']
                                    ).strip()
                                    
                                    # ç„¡åŠ¹ãªæ–‡å­—ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                                    test_text = self._filter_invalid_characters(test_text)
                                    
                                    if test_text:
                                        self.logger.info(f"OCRè¨­å®š{config_idx+1}({img_variant_name}): '{test_text[:30]}{'...' if len(test_text) > 30 else ''}'")
                                        
                                        # æ”¹è‰¯ã•ã‚ŒãŸå“è³ªè©•ä¾¡
                                        text_score = self._evaluate_ocr_quality(test_text, ocr_config)
                                        
                                        if text_score > best_confidence:
                                            best_confidence = text_score
                                            best_text = test_text
                                            self.logger.info(f"æ–°ã—ã„æœ€è‰¯çµæœ: ã‚¹ã‚³ã‚¢{text_score:.1f}, ãƒ†ã‚­ã‚¹ãƒˆ: '{test_text[:20]}...'")
                                            
                                            # ååˆ†ã«è‰¯ã„çµæœãŒå¾—ã‚‰ã‚ŒãŸå ´åˆã¯æ—©æœŸçµ‚äº†
                                            if text_score > 50:
                                                self.logger.info("ååˆ†ãªå“è³ªã®çµæœãŒå¾—ã‚‰ã‚ŒãŸãŸã‚ã€OCRå‡¦ç†ã‚’çµ‚äº†")
                                                break
                                        
                                except Exception as variant_error:
                                    self.logger.debug(f"OCRè¨­å®š{config_idx+1}({img_variant_name})ã§ã‚¨ãƒ©ãƒ¼: {str(variant_error)}")
                                    continue
                            
                            # æ—©æœŸçµ‚äº†æ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
                            if best_confidence > 50:
                                break
                                        
                        except Exception as config_error:
                            self.logger.debug(f"OCRè¨­å®š {ocr_config} ã§ã‚¨ãƒ©ãƒ¼: {str(config_error)}")
                            continue
                    
                    extracted_text = best_text
                    
                    self.logger.info(f"OCRçµæœ (é•·ã• {len(extracted_text)}): '{extracted_text[:50]}{'...' if len(extracted_text) > 50 else ''}'")
                    
                    if extracted_text:
                        ocr_success = True
                        confidence = min(best_confidence / 20.0, 1.0)  # ã‚¹ã‚³ã‚¢ã‚’0-1ã«æ­£è¦åŒ–
                    else:
                        self.logger.info("OCRã§ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                
                except Exception as ocr_error:
                    self.logger.error(f"OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(ocr_error)}")
                
                # çµæœã‚’ä½œæˆï¼ˆOCRãŒå¤±æ•—ã—ã¦ã‚‚ç”»åƒè¦ç´ ã¨ã—ã¦è¨˜éŒ²ï¼‰
                if ocr_success and extracted_text:
                    result_text = extracted_text
                    result_confidence = confidence
                else:
                    result_text = f"ç”»åƒè¦ç´  (OCRå¤±æ•—ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆãªã—) - ã‚µã‚¤ã‚º: {pil_image.size}, æ–¹æ³•: {method}"
                    if crop_info.get("cropped"):
                        result_text += f", åˆ‡ã‚ŠæŠœãã‚µã‚¤ã‚º: {crop_info.get('cropped_size', 'unknown')}"
                    result_confidence = 0.0
                
                result = AnalysisResult(
                    text=result_text,
                    element_type="image",
                    confidence=result_confidence,
                    bbox=element["bbox"],
                    reading_order=0
                )
                results.append(result)
                
                self.logger.info(f"ç”»åƒè¦ç´  {element.get('index', idx)} ã®å‡¦ç†å®Œäº†: '{result_text[:30]}{'...' if len(result_text) > 30 else ''}'")
                
            except Exception as e:
                self.logger.error(f"ç”»åƒè¦ç´ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
                # ã‚¨ãƒ©ãƒ¼ã§ã‚‚çµæœã‚’ä½œæˆ
                error_result = AnalysisResult(
                    text=f"ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)[:50]}",
                    element_type="image",
                    confidence=0.0,
                    bbox=element.get("bbox", (0, 0, 0, 0)),
                    reading_order=0
                )
                results.append(error_result)
        
        self.logger.info(f"OCRå‡¦ç†å®Œäº†: {len(results)}å€‹ã®çµæœ")
        return results
    
    def _preprocess_image_for_ocr(self, pil_image: Image.Image) -> Dict[str, Image.Image]:
        """OCRç”¨ã®ç”»åƒå‰å‡¦ç†"""
        processed_images = {}
        
        try:
            # ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒ
            processed_images["original"] = pil_image
            
            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
            if pil_image.mode != 'L':
                gray_image = pil_image.convert('L')
                processed_images["grayscale"] = gray_image
            
            # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–
            try:
                from PIL import ImageEnhance
                if pil_image.mode != 'L':
                    enhancer = ImageEnhance.Contrast(pil_image.convert('L'))
                else:
                    enhancer = ImageEnhance.Contrast(pil_image)
                contrast_image = enhancer.enhance(2.0)  # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’2å€ã«
                processed_images["contrast"] = contrast_image
            except ImportError:
                self.logger.debug("PIL.ImageEnhance not available, skipping contrast enhancement")
            
            # ãƒªã‚µã‚¤ã‚ºï¼ˆå°ã•ã™ãã‚‹ç”»åƒã‚’æ‹¡å¤§ï¼‰
            if pil_image.width < 100 or pil_image.height < 100:
                scale_factor = max(2, 100 / min(pil_image.width, pil_image.height))
                new_size = (int(pil_image.width * scale_factor), int(pil_image.height * scale_factor))
                resized_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
                processed_images["resized"] = resized_image
            
        except Exception as e:
            self.logger.error(f"ç”»åƒå‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ã¿è¿”ã™
            processed_images = {"original": pil_image}
        
        return processed_images
    
    def _filter_invalid_characters(self, text: str) -> str:
        """ç„¡åŠ¹ãªæ–‡å­—ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        if not text:
            return text
        
        # æ˜ã‚‰ã‹ã«ç„¡åŠ¹ãªæ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»
        invalid_chars = set('Â§Â°Â¢Â£Â¤Â¥Â¦Â©Â«Â®Â±Â²Â³Â´ÂµÂ¶Â·Â¸Â¹ÂºÂ»Â¼Â½Â¾Â¿')
        
        # æ–‡å­—ã‚’1ã¤ãšã¤ãƒã‚§ãƒƒã‚¯
        filtered_chars = []
        for char in text:
            if char not in invalid_chars:
                filtered_chars.append(char)
        
        result = ''.join(filtered_chars)
        
        # é€£ç¶šã™ã‚‹ç‰¹æ®Šæ–‡å­—ã‚„æ„å‘³ä¸æ˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»
        import re
        
        # é€£ç¶šã™ã‚‹|ã‚„è¨˜å·ã‚’é™¤å»
        result = re.sub(r'[|Â§Â°]{2,}', '', result)
        
        # å˜ç‹¬ã®è¨˜å·è¡Œã‚’é™¤å»
        lines = result.split('\n')
        valid_lines = []
        for line in lines:
            line = line.strip()
            # æ—¥æœ¬èªæ–‡å­—ã¾ãŸã¯è‹±æ•°å­—ãŒå«ã¾ã‚Œã‚‹è¡Œã®ã¿ä¿æŒ
            if line and (self._contains_japanese_text(line) or re.search(r'[a-zA-Z0-9]', line)):
                valid_lines.append(line)
        
        return '\n'.join(valid_lines).strip()
    
    def _contains_japanese_text(self, text: str) -> bool:
        """ãƒ†ã‚­ã‚¹ãƒˆã«æ—¥æœ¬èªæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        if not text:
            return False
        
        # ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã®ç¯„å›²ã‚’ãƒã‚§ãƒƒã‚¯
        japanese_ranges = [
            (0x3040, 0x309F),  # ã²ã‚‰ãŒãª
            (0x30A0, 0x30FF),  # ã‚«ã‚¿ã‚«ãƒŠ
            (0x4E00, 0x9FAF),  # CJKçµ±åˆæ¼¢å­—
            (0x3400, 0x4DBF),  # CJKæ‹¡å¼µA
            (0xFF66, 0xFF9D),  # åŠè§’ã‚«ã‚¿ã‚«ãƒŠ
        ]
        
        for char in text:
            char_code = ord(char)
            for start, end in japanese_ranges:
                if start <= char_code <= end:
                    return True
        return False
    
    def _auto_detect_language_ocr(self, pil_image, ocr_config: str, quick_mode: bool) -> str:
        """è¨€èªã‚’è‡ªå‹•æ¤œå‡ºã—ã¦OCRã‚’å®Ÿè¡Œ"""
        # æ—¥æœ¬èªå„ªå…ˆã§è©¦è¡Œ
        text_jpn = pytesseract.image_to_string(pil_image, config=ocr_config, lang='jpn+eng')
        
        if text_jpn.strip() and self._contains_japanese_text(text_jpn):
            if not quick_mode:
                self.logger.info(f"æ—¥æœ¬èªæ¤œå‡º: '{text_jpn[:50]}{'...' if len(text_jpn) > 50 else ''}'")
            return text_jpn
        
        # æ—¥æœ¬èªãŒæ¤œå‡ºã•ã‚Œãªã„å ´åˆã¯è‹±èªã§è©¦è¡Œ
        text_eng = pytesseract.image_to_string(pil_image, config=ocr_config, lang='eng')
        
        if not quick_mode:
            self.logger.info(f"è‹±èªã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: '{text_eng[:50]}{'...' if len(text_eng) > 50 else ''}'")
        
        return text_eng if text_eng.strip() else text_jpn
    
    def _get_ocr_configs_for_language(self, ocr_language: str) -> list:
        """è¨€èªã«å¿œã˜ãŸOCRè¨­å®šã‚’å–å¾—"""
        if ocr_language == 'jpn+eng':
            return [
                # æ—¥æœ¬èªå„ªå…ˆè¨­å®š
                {'lang': 'jpn+eng', 'config': '--psm 6 -c preserve_interword_spaces=1'},
                {'lang': 'jpn', 'config': '--psm 6 -c preserve_interword_spaces=1'},
                {'lang': 'jpn+eng', 'config': '--psm 3'},
                {'lang': 'jpn+eng', 'config': '--psm 7'},
            ]
        elif ocr_language == 'jpn':
            return [
                # æ—¥æœ¬èªã®ã¿
                {'lang': 'jpn', 'config': '--psm 6 -c preserve_interword_spaces=1'},
                {'lang': 'jpn', 'config': '--psm 3'},
                {'lang': 'jpn', 'config': '--psm 7'},
            ]
        elif ocr_language == 'eng':
            return [
                # è‹±èªã®ã¿
                {'lang': 'eng', 'config': '--psm 6 -c preserve_interword_spaces=1'},
                {'lang': 'eng', 'config': '--psm 7 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz.,:-Â¥$â‚¬()[]'},
                {'lang': 'eng', 'config': '--psm 8 -c tessedit_char_whitelist=0123456789.,Â¥$â‚¬'},
            ]
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆæ—¥æœ¬èªå„ªå…ˆï¼‰
            return self._get_ocr_configs_for_language('jpn+eng')
    
    def _evaluate_ocr_quality(self, text: str, ocr_config: dict) -> float:
        """OCRçµæœã®å“è³ªã‚’è©•ä¾¡"""
        if not text or not text.strip():
            return 0.0
        
        score = 0.0
        
        # åŸºæœ¬ã‚¹ã‚³ã‚¢ï¼ˆæ–‡å­—æ•°ï¼‰
        text_length = len(text.replace(' ', '').replace('\n', ''))
        score += min(text_length, 20)  # æœ€å¤§20ç‚¹
        
        # æ—¥æœ¬èªæ–‡å­—ã®æ¤œå‡º
        japanese_chars = sum(1 for char in text if '\u3040' <= char <= '\u309F' or '\u30A0' <= char <= '\u30FF' or '\u4E00' <= char <= '\u9FAF')
        if japanese_chars > 0 and 'jpn' in ocr_config['lang']:
            score += japanese_chars * 2  # æ—¥æœ¬èªæ–‡å­—1ã¤ã«ã¤ã2ç‚¹
        
        # æ•°å­—ã®æ¤œå‡º
        digit_chars = sum(1 for char in text if char.isdigit())
        if digit_chars > 0:
            score += digit_chars * 1.5  # æ•°å­—1ã¤ã«ã¤ã1.5ç‚¹
        
        # è‹±å­—ã®æ¤œå‡º
        alpha_chars = sum(1 for char in text if char.isalpha() and ord(char) < 128)
        if alpha_chars > 0:
            score += alpha_chars * 1  # è‹±å­—1ã¤ã«ã¤ã1ç‚¹
        
        # æ„å‘³ã®ã‚ã‚‹å˜èªãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        import re
        
        # é‡‘é¡ãƒ‘ã‚¿ãƒ¼ãƒ³
        if re.search(r'\d+[,.]?\d*\s*[å††Â¥$â‚¬]', text):
            score += 15
        
        # æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³
        if re.search(r'\d{4}[-/å¹´]\d{1,2}[-/æœˆ]\d{1,2}', text):
            score += 10
        
        # è«‹æ±‚æ›¸é–¢é€£å˜èª
        invoice_words = ['è«‹æ±‚æ›¸', 'é ˜åæ›¸', 'invoice', 'receipt', 'åˆè¨ˆ', 'total', 'ç¨è¾¼', 'ç¨æŠœ']
        for word in invoice_words:
            if word.lower() in text.lower():
                score += 8
        
        # ç„¡åŠ¹æ–‡å­—ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
        invalid_char_count = sum(1 for char in text if char in 'Â§|Â°Â¢Â£Â¤Â¥Â¦Â©Â«Â®Â±Â²Â³Â´ÂµÂ¶Â·Â¸Â¹ÂºÂ»Â¼Â½Â¾Â¿')
        score -= invalid_char_count * 0.5
        
        # æ–‡å­—ã®å¤šæ§˜æ€§ãƒœãƒ¼ãƒŠã‚¹
        unique_chars = len(set(text.replace(' ', '').replace('\n', '')))
        if unique_chars > 5:
            score += min(unique_chars - 5, 10)  # æœ€å¤§10ç‚¹ã®ãƒœãƒ¼ãƒŠã‚¹
        
        return max(score, 0.0)
    
    def _sort_by_reading_order(self, results: List[AnalysisResult]) -> List[AnalysisResult]:
        """åº§æ¨™æƒ…å ±ã«åŸºã¥ã„ã¦èª­ã¿é †ã§ã‚½ãƒ¼ãƒˆï¼ˆYåº§æ¨™è¨±å®¹èª¤å·®å¯¾å¿œï¼‰

        Yåº§æ¨™ãŒè¿‘ã„è¦ç´ ï¼ˆåŒã˜è¡Œï¼‰ã‚’æ­£ã—ãã‚½ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰
        è¨±å®¹èª¤å·®ã‚’èª­ã¿è¾¼ã‚“ã§é©ç”¨ã—ã¾ã™ã€‚

        è¨­å®š: config.toml ã® [ocr] ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        - y_coordinate_tolerance: Yåº§æ¨™ã®è¨±å®¹èª¤å·®ï¼ˆãƒã‚¤ãƒ³ãƒˆå˜ä½ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2.0ï¼‰

        Example:
            å’Œæš¦ã€Œä»¤å’Œ7å¹´9æœˆ16æ—¥ã€ã§æ•°å­—ã¨æ¼¢å­—ã®Yåº§æ¨™ãŒå¾®å¦™ã«ãšã‚Œã¦ã„ã‚‹å ´åˆ:
            - Yåº§æ¨™è¨±å®¹èª¤å·® 2.0 ã®å ´åˆã€56.09ã¨56.43ã¯åŒã˜è¡Œã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹
            - Xåº§æ¨™é †ï¼ˆå·¦ã‹ã‚‰å³ï¼‰ã«ã‚½ãƒ¼ãƒˆ: ä»¤å’Œ 7 å¹´ 9 æœˆ 16 æ—¥

        Returns:
            List[AnalysisResult]: èª­ã¿é †ã§ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸçµæœãƒªã‚¹ãƒˆ
        """
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Yåº§æ¨™è¨±å®¹èª¤å·®ã‚’å–å¾—
        y_tolerance = self.config_manager.get_y_coordinate_tolerance()

        # Yåº§æ¨™ã‚’è¨±å®¹èª¤å·®å†…ã§ä¸¸ã‚ã¦ã‚½ãƒ¼ãƒˆï¼ˆåŒã˜è¡Œã¯Xåº§æ¨™é †ï¼‰
        sorted_results = sorted(
            results,
            key=lambda r: (round(r.bbox[1] / y_tolerance) * y_tolerance, r.bbox[0])
        )

        # reading_orderã‚’è¨­å®š
        for i, result in enumerate(sorted_results):
            result.reading_order = i

        return sorted_results
    
    def combine_results(self, results: List[AnalysisResult]) -> str:
        """åˆ†æçµæœã‚’çµ±åˆã—ã¦å˜ä¸€ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿”ã™"""
        if not results:
            return ""
        
        # èª­ã¿é †ã§ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã®çµæœã‚’çµåˆ
        combined_texts = []
        for result in results:
            if result.text.strip():
                combined_texts.append(result.text.strip())
        
        return ' '.join(combined_texts)
    
    def get_detailed_analysis(self, results: List[AnalysisResult]) -> Dict:
        """è©³ç´°ãªåˆ†ææƒ…å ±ã‚’è¿”ã™"""
        if not results:
            return {
                "total_elements": 0,
                "text_elements": 0,
                "image_elements": 0,
                "combined_text": "é¸æŠç¯„å›²å†…ã«è¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                "average_confidence": 0.0
            }
        
        text_count = sum(1 for r in results if r.element_type == "text")
        image_count = sum(1 for r in results if r.element_type == "image")
        error_count = sum(1 for r in results if r.element_type in ["error", "unknown", "diagnostic"])
        avg_confidence = sum(r.confidence for r in results) / len(results)
        
        return {
            "total_elements": len(results),
            "text_elements": text_count,
            "image_elements": image_count,
            "error_elements": error_count,
            "combined_text": self.combine_results(results),
            "average_confidence": avg_confidence,
            "details": [
                {
                    "text": r.text,
                    "type": r.element_type,
                    "confidence": r.confidence,
                    "bbox": r.bbox
                }
                for r in results
            ]
        }
    
    def _try_ocr_fallback(self, pil_image: Image.Image, element: Dict, idx: int, quick_mode: bool = False) -> Optional[AnalysisResult]:
        """OCRå‡¦ç†å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
        try:
            if not quick_mode:
                self.logger.info(f"OCRãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†é–‹å§‹ (è¦ç´  {idx})")
            
            # 1. ã‚ˆã‚Šç°¡å˜ãªOCRè¨­å®šã§å†è©¦è¡Œ
            fallback_configs = [
                '--psm 8',  # å˜ä¸€ã®å˜èªã¨ã—ã¦æ‰±ã†
                '--psm 7',  # å˜ä¸€ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ©ã‚¤ãƒ³
                '--psm 6',  # å˜ä¸€ã®ãƒ–ãƒ­ãƒƒã‚¯
                '--psm 3',  # è‡ªå‹•çš„ã«ãƒšãƒ¼ã‚¸ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’åˆ¤å®š
            ]
            
            for config in fallback_configs:
                try:
                    text = pytesseract.image_to_string(pil_image, config=config, lang='jpn+eng')
                    if text and text.strip():
                        if not quick_mode:
                            self.logger.info(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ (config: {config}): '{text.strip()[:30]}...'")
                        
                        return AnalysisResult(
                            text=text.strip(),
                            element_type="image_fallback",
                            confidence=0.3,  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãªã®ã§ä½ã‚ã®ä¿¡é ¼åº¦
                            bbox=element.get('bbox', (0, 0, 0, 0)),
                            source="OCR_fallback"
                        )
                except Exception:
                    continue
            
            # 2. ç”»åƒã‚’å‰å‡¦ç†ã—ã¦å†è©¦è¡Œ
            try:
                processed_image = self._simple_image_preprocessing(pil_image)
                text = pytesseract.image_to_string(processed_image, config='--psm 6', lang='jpn+eng')
                if text and text.strip():
                    if not quick_mode:
                        self.logger.info(f"å‰å‡¦ç†ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ: '{text.strip()[:30]}...'")
                    
                    return AnalysisResult(
                        text=text.strip(),
                        element_type="image_preprocessed",
                        confidence=0.2,
                        bbox=element.get('bbox', (0, 0, 0, 0)),
                        source="OCR_preprocessed"
                    )
            except Exception:
                pass
            
            # 3. ç”»åƒæƒ…å ±ã®ã¿ã‚’è¿”ã™ï¼ˆOCRå¤±æ•—ï¼‰
            if not quick_mode:
                self.logger.info(f"å…¨ã¦ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ãŒå¤±æ•—ã€ç”»åƒæƒ…å ±ã®ã¿è¿”å´")
            
            return AnalysisResult(
                text=f"ç”»åƒè¦ç´  (OCRå¤±æ•—) - ã‚µã‚¤ã‚º: {pil_image.size}",
                element_type="image_no_text",
                confidence=0.0,
                bbox=element.get('bbox', (0, 0, 0, 0)),
                source="fallback_image_only"
            )
            
        except Exception as e:
            if not quick_mode:
                self.logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã§ã‚‚ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def _simple_image_preprocessing(self, image: Image.Image) -> Image.Image:
        """OCRãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ç°¡å˜ãªç”»åƒå‰å‡¦ç†"""
        try:
            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
            if image.mode != 'L':
                image = image.convert('L')
            
            # ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã‚‹å ´åˆã¯æ‹¡å¤§
            if image.size[0] < 100 or image.size[1] < 30:
                scale_factor = max(100 / image.size[0], 30 / image.size[1])
                new_size = (int(image.size[0] * scale_factor), int(image.size[1] * scale_factor))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
            
            return image
            
        except Exception:
            return image
    
    def _check_memory_usage(self) -> bool:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        try:
            import psutil
            memory_percent = psutil.virtual_memory().percent
            if memory_percent > 85:  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡85%ä»¥ä¸Šã§è­¦å‘Š
                self.logger.warning(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ããªã£ã¦ã„ã¾ã™: {memory_percent:.1f}%")
                return False
            return True
        except ImportError:
            # psutilãŒãªã„å ´åˆã¯ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—
            return True
        except Exception:
            return True